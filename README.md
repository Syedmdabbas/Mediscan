# Mediscan
A skin cancer detection model
Skin cancer, particularly melanoma and non-melanoma types, presents a growing global health challenge, with incidence rates rising and access to timely diagnosis often limited in rural and underserved areas. Early detection is critical, as it significantly increases survival rates and reduces the need for invasive procedures. However, traditional diagnostic workflows—relying on expert dermatoscopic examination and biopsy—are often inaccessible or delayed due to shortages in trained personnel and diagnostic infrastructure. In response to this challenge, we present mediScan Companion, an end-to-end, AI-powered mobile and edge-compute solution designed to facilitate early detection, simulate lesion progression or healing, and provide patient-centric explanations, all within a unified, accessible platform.
The system integrates multiple advanced deep learning components. It begins with a YOLOv8-based object detection module that isolates skin lesions from dermatoscopic images, followed by an EfficientNet-B4 classifier trained on the HAM10000 dataset to categorize lesions into seven diagnostic classes. For visual simulation of lesion progression and post-treatment healing, the system leverages generative AI via Stable Diffusion combined with ControlNet, fine-tuned on a pseudo-longitudinal organization of the ISIC 2020 dataset. This allows the generation of realistic, high-resolution images depicting the temporal evolution of skin lesions under different conditions.
To improve accessibility and comprehension for non-specialists, a Retrieval-Augmented Generation (RAG) chatbot is integrated into the system. It provides multilingual, patient-friendly explanations of diagnostic outcomes, treatment options, and risk assessments based on both the image analysis and metadata inputs (e.g., patient history, lesion location, and size). Additionally, the system supports interactive augmented reality (AR) via Three.js and WebXR, overlaying the simulated lesion progression on a live camera feed, thus enhancing user engagement and visual understanding of potential disease trajectories.
To maximize usability in low-resource environments, all AI models are quantized and converted to ONNX or TFLite formats, enabling offline inference on edge devices such as smartphones and tablets with limited computational power (as low as 2GB RAM). These components are integrated into an intuitive Streamlit-based web application, allowing real-time image capture, classification, simulation, and explanation through a single interface.
In summary, mediScan Companion addresses multiple challenges in dermatological care—diagnosis accuracy, accessibility, patient understanding, and scalability. Its edge deployment capability and modular design make it especially well-suited for use in remote healthcare.  
